```markdown
# Smart Task API

Una API REST construida con FastAPI para gestionar tareas con sistema de prioridades inteligente.

## Caracter√≠sticas

- Gesti√≥n completa de usuarios y tareas
- Sistema de categor√≠as personalizadas
- Base de datos PostgreSQL
- API documentada autom√°ticamente con Swagger UI
- Arquitectura escalable y mantenible

## Prerrequisitos

- Python 3.11+
- PostgreSQL 12+
- Git

## Instalaci√≥n y Configuraci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/AndyCG03/backend-smart-task
```

### 2. Configurar entorno virtual

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar base de datos PostgreSQL

**Opci√≥n A: Usar PostgreSQL local**

1. Instalar PostgreSQL
2. Crear base de datos:
```sql
CREATE DATABASE smart_task;
```

**Crear Usuario Administrador**

El sistema incluye un script para crear usuarios administradores:

```bash
# Ejecutar el script de creaci√≥n de administrador
python scripts/admin_init.py


### 5. Configurar variables de entorno

Crear archivo `.env` en la ra√≠z del proyecto:

```env
# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/smart_task

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# App
DEBUG=true
```

### 6. Ejecutar la aplicaci√≥n

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## Estructura del Proyecto

```
app/
‚îú‚îÄ‚îÄ main.py                 # Punto de entrada de la aplicaci√≥n
‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n y variables de entorno
‚îú‚îÄ‚îÄ database.py            # Conexi√≥n a la base de datos
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ database_models.py # Modelos de SQLAlchemy
‚îÇ   ‚îî‚îÄ‚îÄ pydantic_models.py # Schemas Pydantic para validaci√≥n
‚îî‚îÄ‚îÄ api/
    ‚îú‚îÄ‚îÄ routes.py          # Router principal
    ‚îî‚îÄ‚îÄ endpoints/         # Endpoints de la API
        ‚îú‚îÄ‚îÄ users.py       # Gesti√≥n de usuarios
        ‚îú‚îÄ‚îÄ tasks.py       # Gesti√≥n de tareas
        ‚îú‚îÄ‚îÄ categories.py  # Gesti√≥n de categor√≠as
        ‚îú‚îÄ‚îÄ recommendations.py # Recomendaciones diarias
        ‚îú‚îÄ‚îÄ energy_logs.py # Registros de energ√≠a
        ‚îî‚îÄ‚îÄ task_history.py # Historial de tareas
```

## Modelo de Datos

### Tablas Principales:

- **users**: Gesti√≥n de usuarios y preferencias
- **tasks**: Tareas con sistema de prioridad
- **categories**: Categor√≠as personalizadas por usuario
- **daily_recommendations**: Recomendaciones diarias
- **energy_logs**: Registros de niveles de energ√≠a
- **task_history**: Historial de cambios en tareas

## Endpoints de la API

### Usuarios
- `GET /api/v1/users/` - Listar usuarios
- `GET /api/v1/users/{user_id}` - Obtener usuario espec√≠fico
- `POST /api/v1/users/` - Crear usuario
- `PUT /api/v1/users/{user_id}` - Actualizar usuario

### Tareas
- `GET /api/v1/tasks/` - Listar tareas
- `GET /api/v1/tasks/{task_id}` - Obtener tarea espec√≠fica
- `POST /api/v1/tasks/` - Crear tarea
- `PUT /api/v1/tasks/{task_id}` - Actualizar tarea
- `DELETE /api/v1/tasks/{task_id}` - Eliminar tarea

### Categor√≠as
- `GET /api/v1/categories/` - Listar categor√≠as de usuario
- `GET /api/v1/categories/{category_id}` - Obtener categor√≠a espec√≠fica
- `POST /api/v1/categories/` - Crear categor√≠a
- `PUT /api/v1/categories/{category_id}` - Actualizar categor√≠a
- `DELETE /api/v1/categories/{category_id}` - Eliminar categor√≠a

### Recomendaciones
- `GET /api/v1/recommendations/` - Listar recomendaciones
- `GET /api/v1/recommendations/{recommendation_id}` - Obtener recomendaci√≥n espec√≠fica
- `POST /api/v1/recommendations/` - Crear recomendaci√≥n
- `PUT /api/v1/recommendations/{recommendation_id}` - Actualizar recomendaci√≥n
- `PUT /api/v1/recommendations/{recommendation_id}/status` - Actualizar estado

### Registros de Energ√≠a
- `GET /api/v1/energy-logs/` - Listar registros de energ√≠a
- `GET /api/v1/energy-logs/{log_id}` - Obtener registro espec√≠fico
- `POST /api/v1/energy-logs/` - Crear registro
- `PUT /api/v1/energy-logs/{log_id}` - Actualizar registro
- `DELETE /api/v1/energy-logs/{log_id}` - Eliminar registro

### Historial de Tareas
- `GET /api/v1/task-history/task/{task_id}` - Historial de una tarea
- `GET /api/v1/task-history/user/{user_id}` - Historial de usuario
- `GET /api/v1/task-history/{history_id}` - Entrada espec√≠fica de historial

## Documentaci√≥n de la API

Una vez ejecutada la aplicaci√≥n, la documentaci√≥n autom√°tica estar√° disponible en:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Ejemplos de Uso

### Crear un usuario

```bash
curl -X POST "http://localhost:8000/api/v1/users/" \
-H "Content-Type: application/json" \
-d '{
  "email": "usuario@ejemplo.com",
  "name": "Juan P√©rez",
  "password": "password123",
  "energy_level": "medium"
}'
```

### Crear una tarea

```bash
curl -X POST "http://localhost:8000/api/v1/tasks/" \
-H "Content-Type: application/json" \
-d '{
  "title": "Completar documentaci√≥n",
  "description": "Terminar el README del proyecto",
  "urgency": "high",
  "impact": "high",
  "estimated_duration": 120,
  "user_id": "uuid-del-usuario"
}'
```

## Sistema de Inteligencia Artificial

El sistema incorpora un modelo de Machine Learning para la priorizaci√≥n inteligente de tareas y recomendaciones personalizadas, con capacidad de aprendizaje continuo y adaptaci√≥n contextual en tiempo real.

### Arquitectura del Sistema IA

#### Componentes Principales

1. **TaskAgent** - Motor principal de ML con post-procesamiento contextual
2. **Modelos de Base de Datos** - Almacenamiento de modelos y datos de entrenamiento  
3. **Endpoints ML** - API para interactuar con el sistema IA

#### Flujo de Trabajo del Agent

![Flujo de trabajo](images/TaskAgent.drawio.png)

### Arquitectura T√©cnica del Sistema Agent

#### Flujo de Entrenamiento del Modelo

##### 1. **Recolecci√≥n de Datos**
```python
# Datos recolectados de tareas completadas
{
    "titulo": "Fix bug producci√≥n - servicio ca√≠do",
    "descripcion": "Servicio cr√≠tico no responde, resolver inmediatamente",
    "urgencia": "high",
    "impacto": "high",
    "energia_requerida": "high",
    "duracion_estimada": 60,
    "eficiencia": 1.71  # calculada autom√°ticamente
}
```

##### 2. **Preprocesamiento de Caracter√≠sticas**
```python
# Caracter√≠sticas extra√≠das para el modelo:
features = {
    'urgencia_encoded': 2,           # Label Encoding: low=0, medium=1, high=2
    'impacto_encoded': 2,            # Label Encoding: low=0, medium=1, high=2  
    'energia_encoded': 2,            # Label Encoding: low=0, medium=1, high=2
    'duracion_estimada': 60,         # Minutos estimados
    'longitud_descripcion': 58,      # Caracteres en descripci√≥n
    'tiene_urgente': 1,              # 1 si contiene "urgent", "cr√≠tic"
    'tiene_bug': 1                   # 1 si contiene "bug", "fix"
}
```

##### 3. **Variable Objetivo: Eficiencia**
La m√©trica clave que el modelo aprende a predecir:

```python
def calcular_eficiencia(task):
    # Si hay feedback de tiempo real:
    if feedback.actual_completion_time and task.estimated_duration:
        return task.estimated_duration / max(feedback.actual_completion_time, 1)
    
    # Fallback: usar prioridad como proxy
    prioridad_map = {"high": 2.0, "medium": 1.0, "low": 0.5}
    return prioridad_map.get(task.priority_level, 1.0)
```

**Interpretaci√≥n de Eficiencia:**
- `> 1.0`: Se complet√≥ m√°s r√°pido de lo estimado (BUENO)
- `= 1.0`: Se complet√≥ en el tiempo estimado (NEUTRO)  
- `< 1.0`: Se complet√≥ m√°s lento de lo estimado (MALO)

### Algoritmo de Machine Learning

#### Modelo: SGDRegressor
```python
modelo = SGDRegressor(
    max_iter=1000,           # M√°ximo de iteraciones
    tol=1e-3,                # Tolerancia para convergencia
    random_state=42,         # Semilla para reproducibilidad
    learning_rate='adaptive', # Tasa de aprendizaje adaptativa
    eta0=0.1                 # Tasa de aprendizaje inicial
)
```

#### Caracter√≠sticas del Algoritmo:
- **Online Learning**: Aprende incrementalmente con nuevos datos
- **Eficiente en Memoria**: No necesita cargar todos los datos a la vez
- **Adaptativo**: Se ajusta autom√°ticamente a nuevos patrones

### Proceso de Predicci√≥n y Post-procesamiento

#### 1. **Para tareas pendientes:**
```python
# Extraer caracter√≠sticas en tiempo real
X_pred = [
    [2, 2, 2, 60, 58, 1, 1],  # Tarea cr√≠tica
    [1, 1, 1, 120, 45, 0, 0]  # Tarea de mantenimiento
]

# Hacer predicci√≥n
scores_ml = modelo.predict(X_pred)
# Resultado: [17.55, 4.27]

# Aplicar post-procesamiento contextual
scores_ajustados = []
for score, task in zip(scores_ml, tasks):
    ajuste = 1.0
    if hora_actual >= 18 and task.energy_required == "high":
        ajuste = 0.7
    scores_ajustados.append(score * ajuste)
```

#### 2. **Interpretaci√≥n de Scores:**
- **Alto Score (15-20)**: Tareas cr√≠ticas que suelen completarse r√°pido
- **Medio Score (8-14)**: Tareas importantes con tiempo normal
- **Bajo Score (1-7)**: Tareas de mantenimiento que toman m√°s tiempo

### Post-procesamiento Contextual

Despu√©s de la predicci√≥n inicial (ML o reglas), se aplica un **ajuste contextual** para adaptar las recomendaciones al momento actual del usuario:

```python
def _post_procesamiento(self, resultados):
    hora_actual = datetime.now().hour
    
    # Penalizar tareas de alta energ√≠a al final del d√≠a
    if hora_actual >= 18 and task.energy_required == "high":
        puntaje_ml *= 0.7
        
    # Favorecer tareas ligeras en la noche
    if hora_actual >= 18 and task.energy_required == "low":
        puntaje_ml *= 1.2
        
    # Impulso leve para tareas con feedback negativo reciente
    if task.id in feedback_negativo_reciente:
        puntaje_ml *= 1.1
```

**Objetivos del post-procesamiento:**
- Evitar sugerir tareas exigentes cuando el usuario probablemente est√° cansado
- Aprovechar momentos de alta energ√≠a para tareas cr√≠ticas
- Dar seguimiento temporal a feedback reciente del usuario

### Persistencia del Modelo

#### Almacenamiento en PostgreSQL:
```sql
-- Tabla ai_models
id UUID PRIMARY KEY,
user_id UUID REFERENCES users(id),
model_type VARCHAR(50),        -- "priority_predictor_v2"
model_version VARCHAR(20),     -- "2.0"
model_data BYTEA,              -- Modelo serializado con joblib
feature_weights JSONB,         -- Pesos de caracter√≠sticas
accuracy_metrics JSONB,        -- M√©tricas de precisi√≥n
is_active BOOLEAN,             -- Modelo activo
trained_at TIMESTAMP
```

#### Serializaci√≥n con Joblib:
```python
# Guardar modelo
buffer = BytesIO()
joblib.dump(modelo, buffer)
modelo_bin = buffer.getvalue()

# Cargar modelo
modelo = joblib.load(BytesIO(modelo_bin))
```

### Sistema de Fallback con Reglas

Cuando no hay suficientes datos para entrenar (< 2 tareas completadas):

```python
def _prioridad_por_reglas(self, tasks):
    prioridad_map = {"high": 3, "medium": 2, "low": 1}
    
    for task in tasks:
        puntaje = prioridad_map.get(task.priority_level, 1)
        
        # Bonus por palabras clave
        if any(word in task.title.lower() for word in ['bug', 'fix', 'cr√≠tic']):
            puntaje *= 1.8
            
        # Bonus por urgencia e impacto
        if task.urgency == "high":
            puntaje *= 1.5
        if task.impact == "high":
            puntaje *= 1.3
            
        task.puntaje_ml = float(puntaje)
```

### Proceso de Feedback y Mejora Continua

#### 1. **Tipos de Feedback:**
```python
MLFeedback(
    feedback_type="priority",          # priority, schedule, completion
    was_useful=True,                   # Si la predicci√≥n fue √∫til
    actual_priority="high",            # Prioridad real que tuvo
    actual_completion_time=35          # Tiempo real en minutos
)
```

#### 2. **Reentrenamiento Autom√°tico:**
- Se activa cuando `was_useful=False` **(feedback negativo)**, lo que:
  1. **Dispara un reentrenamiento inmediato** del modelo con los datos actualizados
  2. **Aplica un impulso temporal** (10%) a esa tarea espec√≠fica durante las pr√≥ximas 24h en el post-procesamiento
- Usa todos los datos hist√≥ricos + nuevo feedback
- Crea nueva versi√≥n del modelo
- Mantiene modelo anterior como backup

### M√©tricas de Evaluaci√≥n

#### Validaci√≥n con Datos Reales:
```python
# Resultados del demo avanzado
{
    "tareas_criticas_score_promedio": 17.55,
    "tareas_mantenimiento_score_promedio": 4.27,
    "diferencia": 13.28,
    "ratio_priorizacion": 4.28  # 428% m√°s prioridad
}
```

#### Indicadores de Calidad:
- **Consistencia**: Mismo tipo de tarea ‚Üí Score similar
- **Diferenciaci√≥n**: Tipos diferentes ‚Üí Scores diferentes  
- **Alineaci√≥n con Comportamiento**: Scores reflejan patrones reales de uso

### Requisitos de Datos M√≠nimos

#### Para Entrenamiento Inicial:
- **M√≠nimo**: 2 tareas completadas
- **√ìptimo**: 5+ tareas completadas
- **Ideal**: 10+ tareas con feedback de tiempo real

#### Calidad de Datos:
- Tareas con descripciones detalladas
- Tiempos reales de completado (feedback)
- Variedad en tipos de tareas
- Prioridades realistas asignadas

### Limitaciones y Consideraciones

#### Casos Edge:
- **Nuevos usuarios**: Usa sistema de reglas hasta tener datos
- **Tareas at√≠picas**: Pueden requerir ajuste manual
- **Cambios de patrones**: El modelo se adapta gradualmente

#### Performance:
- **Entrenamiento**: ~1-2 segundos con 10-20 tareas
- **Predicci√≥n**: ~100ms por lote de tareas
- **Almacenamiento**: ~1-5MB por modelo de usuario

### Endpoints de Machine Learning

#### 1. Obtener Tareas Priorizadas por ML
```http
GET /api/v1/ml_tasks/prioritized
```

**Descripci√≥n:** Obtiene las tareas pendientes ordenadas por el score de prioridad calculado por el modelo ML (incluyendo ajustes de post-procesamiento contextual).

**Ejemplo de respuesta:**
```json
[
  {
    "id": "uuid-tarea",
    "title": "Enviar reporte trimestral",
    "priority_level": "high",
    "ml_priority_score": 4.2,
    "estimated_duration": 120,
    "urgency": "high",
    "impact": "high"
  }
]
```

**Uso:**
```bash
curl -H "Authorization: Bearer {token}" \
  "http://localhost:8000/api/v1/ml_tasks/prioritized"
```

#### 2. Entrenar Modelo para Tarea
```http
POST /api/v1/ml_tasks/{task_id}/train
```

**Descripci√≥n:** Entrena el modelo ML cuando se completa una tarea, usando los datos reales de ejecuci√≥n.

**Ejemplo:**
```bash
curl -X POST -H "Authorization: Bearer {token}" \
  "http://localhost:8000/api/v1/ml_tasks/123e4567-e89b-12d3-a456-426614174000/train"
```

**Respuesta:**
```json
{
  "message": "Modelo actualizado exitosamente",
  "trained": true
}
```

#### 3. Obtener Horario Recomendado
```http
GET /api/v1/ml_tasks/{task_id}/recommended-time
```

**Descripci√≥n:** Obtiene el horario √≥ptimo recomendado para ejecutar una tarea espec√≠fica basado en su nivel de energ√≠a requerido y tipo de tarea.

**Ejemplo:**
```bash
curl -H "Authorization: Bearer {token}" \
  "http://localhost:8000/api/v1/ml_tasks/123e4567-e89b-12d3-a456-426614174000/recommended-time"
```

**Respuesta:**
```json
{
  "task_id": "123e4567-e89b-12d3-a456-426614174000",
  "recommended_time": "08:00",
  "message": "Horario recomendado: 08:00"
}
```

#### 4. Enviar Feedback ML
```http
POST /api/v1/ml_tasks/{task_id}/feedback
```

**Par√°metros en cuerpo (JSON):**
- `feedback_type`: Tipo de feedback (priority, schedule, completion)
- `was_useful`: Si la predicci√≥n fue √∫til (true/false)
- `actual_priority`: Prioridad real que tuvo la tarea (opcional)
- `actual_completion_time`: Tiempo real de completado en minutos (opcional)

**Ejemplo:**
```bash
curl -X POST \
  "http://localhost:8000/api/v1/ml_tasks/123e4567-e89b-12d3-a456-426614174000/feedback" \
  -H "Authorization: Bearer {token}" \
  -H "Content-Type: application/json" \
  -d '{
    "feedback_type": "completion",
    "was_useful": true,
    "actual_completion_time": 35
  }'
```

**Respuesta:**
```json
{
  "message": "Feedback registrado exitosamente"
}
```

### Scripts de Simulaci√≥n y Diagn√≥stico

#### 1. Script de Diagn√≥stico ML (`scripts/diagnosticar_ml.sh`)

**Prop√≥sito:** Verificar el funcionamiento de todos los endpoints ML y diagnosticar problemas.

**Uso:**
```bash
chmod +x scripts/diagnosticar_ml.sh
./scripts/diagnosticar_ml.sh
```

**Funcionalidades:**
- Verifica autenticaci√≥n
- Prueba todos los endpoints ML
- Muestra scores de priorizaci√≥n
- Detecta problemas de configuraci√≥n

#### 2. Script de Inicializaci√≥n de Simulaci√≥n (`scripts/simulation/admin_init_simulation.py`)

**Prop√≥sito:** Inicializar la base de datos con datos de prueba y usuario administrador.

**Uso:**
```bash
python scripts/simulation/admin_init_simulation.py
```

**Funcionalidades:**
- Crea tablas de base de datos
- Genera usuario administrador
- Crea categor√≠as de ejemplo
- Genera tareas de entrenamiento inicial

**Credenciales por defecto:**
- Email: `admin@taskapp.com`
- Contrase√±a: `Admin123!`

#### 3. Script Principal de Simulaci√≥n (`simulate3.sh`)

**Prop√≥sito:** Ejecutar un flujo completo de demostraci√≥n del sistema ML con validaci√≥n de aprendizaje.

**Uso:**
```bash
chmod +x simulate3.sh
./simulate3.sh
```

**Flujo de la Simulaci√≥n:**

1. **Inicializaci√≥n:** Base de datos y usuario admin
2. **Autenticaci√≥n:** Login con JWT
3. **Creaci√≥n de Tareas:** Tareas con patrones de comportamiento claros (cr√≠ticas vs mantenimiento)
4. **Integraci√≥n ML:** 
   - Completado de tareas con tiempos reales
   - Entrenamiento del modelo
   - Validaci√≥n expl√≠cita de que el modelo aprende
   - Feedback del usuario
5. **Estad√≠sticas:** Resumen del aprendizaje con m√©tricas de diferenciaci√≥n

### Caracter√≠sticas del Modelo ML

#### Algoritmos Utilizados
- **SGDRegressor** para predicci√≥n de prioridades
- **TF-IDF Vectorizer** para an√°lisis de texto en descripciones (reservado para futuras mejoras)
- **Label Encoding** para variables categ√≥ricas
- **Sistema de Reglas** como fallback cuando no hay datos suficientes
- **Post-procesamiento Contextual** para adaptaci√≥n en tiempo real

#### Caracter√≠sticas Consideradas
- Texto de descripci√≥n y t√≠tulo (palabras clave)
- Nivel de urgencia e impacto
- Fecha l√≠mite y tiempo estimado
- Nivel de energ√≠a requerido
- Historial de completado del usuario
- Hora actual del d√≠a (post-procesamiento)
- Feedback reciente del usuario (post-procesamiento)

#### Persistencia del Modelo
Los modelos entrenados se almacenan en la base de datos PostgreSQL en la tabla `ai_models`, permitiendo:
- Recuperaci√≥n despu√©s de reinicios
- M√∫ltiples versiones de modelos
- Activaci√≥n/desactivaci√≥n de modelos

### Requisitos para el Funcionamiento ML

#### Dependencias
```bash
pip install scikit-learn pandas numpy joblib
```

#### Datos M√≠nimos
- M√≠nimo 2 tareas completadas para entrenamiento inicial
- Tareas con fechas l√≠mite para mejor precisi√≥n
- Feedback del usuario para ajuste continuo

### Ejemplo de Flujo Completo

```bash
# 1. Inicializar sistema
python scripts/simulation/admin_init_simulation.py

# 2. Ejecutar simulaci√≥n completa
./simulate3.sh

# 3. Diagnosticar ML espec√≠ficamente  
./scripts/diagnosticar_ml.sh

# 4. Ver documentaci√≥n API
# http://localhost:8000/docs
```

### üîÅ ¬øCu√°ndo y c√≥mo se entrena el modelo de IA?

El sistema de inteligencia artificial **no se entrena autom√°ticamente en segundo plano**. En cambio, el entrenamiento se **dispara de forma intencional** en dos momentos muy espec√≠ficos, y siempre se basa en **datos reales de tu comportamiento** como usuario.

#### üìå ¬øQu√© desencadena el entrenamiento?

El entrenamiento ocurre en **dos situaciones**:

1. **Cuando completas una tarea y env√≠as feedback de tiempo real**  
   Si marcas una tarea como "completada" y proporcionas cu√°nto tiempo **realmente** te tom√≥ terminarla (por ejemplo, estimaste 60 minutos pero tardaste 35), el sistema **puede entrenarse** si hay suficientes datos acumulados.

2. **Cuando indicas que una recomendaci√≥n del sistema fue incorrecta**  
   Si el sistema te sugiere una prioridad para una tarea y t√∫ respondes **"no fue √∫til"** (`was_useful=false`), esto **dispara inmediatamente un reentrenamiento**. La idea es: *"El modelo se equivoc√≥, as√≠ que aprende de este error ahora mismo."*

En ambos casos, **t√∫ controlas cu√°ndo el sistema aprende**, ya sea al completar tareas con datos reales o al corregir sus errores.

#### üìä ¬øCon qu√© datos se entrena?

El modelo **solo se entrena con tareas que ya completaste** y que tienen **informaci√≥n real de ejecuci√≥n**. Espec√≠ficamente, necesita:

- **Tus tareas marcadas como "completed"**
- **Tiempo estimado** (el que t√∫ asignaste al crear la tarea)
- **Tiempo real** (el que t√∫ reportaste al completarla, a trav√©s del feedback)

Con estos datos, el sistema calcula una m√©trica clave llamada **"eficiencia"**:
```
Eficiencia = Tiempo estimado / Tiempo real
```

- Si completaste una tarea de 60 minutos en solo 30 minutos ‚Üí Eficiencia = 2.0 ‚úÖ (¬°muy eficiente!)
- Si completaste una tarea de 30 minutos en 60 minutos ‚Üí Eficiencia = 0.5 ‚ùå (menos eficiente)

Adem√°s, el sistema tambi√©n considera:
- El **t√≠tulo y descripci√≥n** de la tarea (para detectar si es un "bug", "urgente", etc.)
- Los **metadatos** que asignaste (urgencia, impacto, energ√≠a requerida)
- La **prioridad original** que le diste

#### ‚öôÔ∏è ¬øC√≥mo funciona el entrenamiento paso a paso?

1. **Recopilaci√≥n**: El sistema busca **todas tus tareas completadas** que tienen tiempo real registrado.
2. **Preparaci√≥n**: Convierte cada tarea en un conjunto de n√∫meros (caracter√≠sticas) que el modelo puede entender:
   - C√≥digo num√©rico para urgencia, impacto y energ√≠a
   - N√∫meros que indican si la tarea habla de "bugs" o "urgencias"
   - Duraci√≥n estimada y longitud de la descripci√≥n
3. **Aprendizaje**: El modelo **SGDRegressor** analiza estas caracter√≠sticas y aprende a predecir la **"eficiencia"** esperada para tareas similares.
4. **Guardado**: Si el entrenamiento tiene √©xito, el nuevo modelo se guarda en la base de datos y se activa autom√°ticamente para futuras predicciones.

#### ‚è±Ô∏è ¬øCu√°ntos datos se necesitan?

- **M√≠nimo absoluto**: 2 tareas completadas con feedback de tiempo real.
- **Recomendado**: 5 o m√°s tareas para que el modelo comience a hacer predicciones √∫tiles.
- **Ideal**: Cuantas m√°s tareas completes con datos reales, mejor ser√° el modelo.

#### üîç ¬øQu√© pasa si no hay suficientes datos?

Si tienes menos de 2 tareas completadas, el sistema **no entrena ning√∫n modelo**. En su lugar, usa un **sistema de reglas inteligentes** basado en:
- Palabras clave en el t√≠tulo/descripci√≥n ("bug", "urgente", "cr√≠tico")
- Los niveles de urgencia e impacto que asignaste
- La cercan√≠a de la fecha l√≠mite

Este sistema de reglas **siempre est√° disponible** como plan de respaldo, asegurando que siempre recibas recomendaciones, incluso si eres un usuario nuevo.

#### üí° En resumen

- **T√∫ decides cu√°ndo el sistema aprende**: al completar tareas con tiempo real o al corregir errores.
- **El modelo se entrena solo con tu historial personal**: no usa datos de otros usuarios.
- **El objetivo es predecir qu√© tareas merecen prioridad** porque **t√∫ las completas eficientemente** (r√°pido y bien).
- **Siempre hay un plan B**: el sistema de reglas garantiza funcionalidad desde el primer d√≠a.

### ü§î ¬øPor qu√© usamos SGDRegressor y no otro algoritmo de Machine Learning?

Al dise√±ar el sistema de priorizaci√≥n inteligente, evaluamos varias opciones de algoritmos de machine learning. Elegimos **SGDRegressor** (Stochastic Gradient Descent Regressor) no por ser el m√°s avanzado, sino por ser el **m√°s adecuado** para las necesidades espec√≠ficas de un sistema de productividad personal. Aqu√≠ te explicamos por qu√©.

#### üéØ Requisitos clave del sistema

Antes de elegir un algoritmo, definimos lo que **realmente necesit√°bamos**:

1. **Ligereza**: El sistema debe funcionar r√°pido, incluso en dispositivos con recursos limitados.
2. **Aprendizaje incremental**: Debe poder aprender de **pocos datos** (muchos usuarios tendr√°n solo unas pocas tareas completadas al principio).
3. **Bajo costo computacional**: El entrenamiento no debe ralentizar la aplicaci√≥n ni consumir mucha memoria.
4. **Interpretabilidad parcial**: Si algo falla, debemos poder entender por qu√©.
5. **Personalizaci√≥n por usuario**: Cada usuario tiene su propio modelo, as√≠ que necesitamos algo que se pueda entrenar y guardar f√°cilmente miles de veces.

#### ‚ùå ¬øPor qu√© NO usamos otros algoritmos?

- **Redes neuronales**: Requieren muchos datos para entrenar bien y son "cajas negras". Si el modelo se equivoca, es muy dif√≠cil entender por qu√©. Adem√°s, son pesadas para un sistema que debe responder en milisegundos.

- **√Årboles de decisi√≥n o Random Forest**: Aunque son interpretables, **no funcionan bien con pocos datos** (menos de 10-20 ejemplos). Tambi√©n consumen m√°s memoria y son m√°s lentos para guardar/cargar.

- **Regresi√≥n lineal cl√°sica**: Es ligera, pero **no maneja bien el aprendizaje incremental**. Cada vez que se a√±ade un nuevo dato, hay que reentrenar todo desde cero, lo que es ineficiente.

- **Modelos basados en instancias (como K-NN)**: Requieren guardar **todos los datos hist√≥ricos** en memoria para hacer predicciones, lo que no escala bien cuando un usuario tiene cientos de tareas.

#### ‚úÖ ¬øPor qu√© S√ç SGDRegressor?

SGDRegressor cumple **perfectamente** con todos nuestros requisitos:

- **Extremadamente ligero**: Usa muy poca memoria y CPU, ideal para entrenamientos r√°pidos.
- **Aprendizaje con pocos datos**: Aunque el modelo mejora con m√°s datos, puede **empezar a aprender con solo 2-3 tareas completadas**, lo que es crucial para usuarios nuevos.
- **Entrenamiento eficiente**: Procesa los datos de forma secuencial y **no necesita cargar todo el dataset en memoria**, lo que lo hace ideal para entornos con recursos limitados.
- **Compatible con el flujo de usuario**: Cada vez que completas una tarea, el sistema puede **actualizar el modelo r√°pidamente** sin reiniciar todo.
- **Suficientemente potente**: Aunque es un modelo lineal, al combinarlo con **caracter√≠sticas bien dise√±adas** (como "tiene_bug", "urgencia_codificada", etc.), logra capturar patrones complejos de comportamiento.
- **F√°cil de guardar y cargar**: El modelo entrenado ocupa muy poco espacio (1-5 MB) y se serializa f√°cilmente con `joblib`, lo que permite almacenarlo en la base de datos sin problemas.

#### üí° Analog√≠a simple

Piensa en SGDRegressor como un **estudiante muy eficiente**:
- No necesita leer cientos de libros para aprender (pocos datos bastan).
- Aprende de cada experiencia nueva inmediatamente.
- No ocupa mucho espacio en su escritorio (bajo consumo de memoria).
- Puede explicar sus decisiones en t√©rminos simples ("le doy m√°s prioridad a las tareas con 'bug' porque hist√≥ricamente las completas r√°pido").

En cambio, otros algoritmos ser√≠an como estudiantes que necesitan una biblioteca completa, mucho tiempo de estudio y espacio de trabajo, lo que no es pr√°ctico para un sistema de productividad personal.

#### üìä Resultado en la pr√°ctica

Gracias a esta elecci√≥n:
- El **entrenamiento toma menos de 2 segundos** incluso en servidores modestos.
- La **predicci√≥n es casi instant√°nea** (menos de 100ms para decenas de tareas).
- El sistema **empieza a ser √∫til desde el primer d√≠a**, sin necesidad de un largo per√≠odo de "entrenamiento inicial".
- El **consumo de recursos es m√≠nimo**, permitiendo ejecutar el sistema en casi cualquier entorno.

### Soluci√≥n de Problemas ML

#### Error: "No hay suficientes datos para entrenar"
**Soluci√≥n:** Completar m√°s tareas para generar historial de entrenamiento (m√≠nimo 2 tareas completadas).

#### Error: "Endpoints ML no disponibles"
**Soluci√≥n:** Verificar que las rutas usen **`/ml_tasks/`** (con gui√≥n bajo `_`) y no `/ml-tasks/`. Verificar que las dependencias de ML est√©n instaladas y reiniciar el servidor.

#### Error: "Modelo no carga correctamente"
**Soluci√≥n:** Ejecutar el script de diagn√≥stico para identificar el problema espec√≠fico. Verificar permisos de base de datos y espacio de almacenamiento.

## Configuraci√≥n de Desarrollo

### Variables de Entorno

| Variable | Descripci√≥n | Valor por Defecto |
|----------|-------------|-------------------|
| DATABASE_URL | URL de conexi√≥n a PostgreSQL | postgresql://postgres:password@localhost:5432/smart_task |
| ALLOWED_ORIGINS | Or√≠genes permitidos para CORS | http://localhost:3000,http://127.0.0.1:3000 |
| DEBUG | Modo debug | true |

### Dependencias Principales

- FastAPI - Framework web
- SQLAlchemy - ORM para base de datos
- PostgreSQL - Base de datos
- Uvicorn - Servidor ASGI
- Pydantic - Validaci√≥n de datos

## Soluci√≥n de Problemas

### Error: "ModuleNotFoundError: No module named 'app.api.users'"

Eliminar el archivo `app/api/__init__.py` si existe.

### Error: "No module named 'psycopg2'"

Ejecutar:
```bash
pip install psycopg2-binary
```

### Error de conexi√≥n a la base de datos

Verificar que:
1. PostgreSQL est√© ejecut√°ndose
2. Las credenciales en `.env` sean correctas
3. La base de datos `smart_task` exista

### Limpiar cach√© de Python

```bash
# Eliminar archivos __pycache__
find . -name "__pycache__" -type d -exec rm -rf {} +
```

## Pr√≥ximos Pasos

- [ ] Implementar autenticaci√≥n JWT
- [ ] Agregar sistema de IA para priorizaci√≥n
- [ ] Implementar tests unitarios
- [ ] Configurar CI/CD
- [ ] Dockerizar la aplicaci√≥n

